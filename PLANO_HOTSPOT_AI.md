# ğŸ“‹ Plano de ImplementaÃ§Ã£o: Comando `\hotspot-ai`

## ğŸ¯ Objetivo
Implementar comando `\hotspot-ai <table>` que utiliza LLM configurada para analisar hotspots em tabelas do Google Cloud Spanner, identificando problemas de design que podem causar hotspots.

---

## ğŸ“ Arquitetura da SoluÃ§Ã£o

### Fluxo de ExecuÃ§Ã£o
```
\hotspot-ai <table>
    â†“
1. Validar tabela existe
    â†“
2. Obter DDL COMPLETA do banco de dados:
   - Todas as tabelas
   - Todos os Ã­ndices
   - Todas as sequences
   - Todas as funÃ§Ãµes
   (usar \da internamente - DDL completa)
    â†“
3. Obter informaÃ§Ãµes adicionais da tabela especÃ­fica:
   - Primary Key e tipo
   - Ãndices secundÃ¡rios
   - Colunas e tipos
   - Default values (para detectar sequÃªncias)
    â†“
4. Verificar LLM configurada
    â†“
5. Construir prompt estruturado
   (incluir DDL completa + metadados da tabela)
    â†“
6. Chamar API OpenAI
    â†“
7. Processar resposta JSON
    â†“
8. Formatar saÃ­da (similar ao exemplo)
```

---

## ğŸ”§ Componentes a Implementar

### 1. FunÃ§Ã£o: `get_full_database_ddl()`
**LocalizaÃ§Ã£o:** ApÃ³s funÃ§Ã£o `get_column_type()` (linha ~757)

**Responsabilidade:**
- Obter DDL COMPLETA do banco de dados usando `gcloud spanner databases ddl describe`
- Incluir TODOS os objetos:
  - Todas as tabelas (CREATE TABLE)
  - Todos os Ã­ndices (CREATE INDEX)
  - Todas as sequences (CREATE SEQUENCE)
  - Todas as funÃ§Ãµes (CREATE FUNCTION)
- Retornar DDL completa como string

**Entrada:** Nenhuma (usa DATABASE_ID e INSTANCE_ID globais)
**SaÃ­da:** DDL completa do banco (todos os objetos)

**ImplementaÃ§Ã£o:**
```bash
get_full_database_ddl() {
  gcloud spanner databases ddl describe ${DATABASE_ID} \
    --instance=${INSTANCE_ID} 2>/dev/null
}
```

**Nota:** Esta funÃ§Ã£o retorna TUDO do banco, nÃ£o apenas uma tabela especÃ­fica. Isso permite Ã  LLM analisar:
- **Sequences compartilhadas:** Se uma sequence Ã© usada em mÃºltiplas tabelas, pode indicar padrÃ£o de design
- **FunÃ§Ãµes customizadas:** FunÃ§Ãµes usadas em DEFAULT podem afetar geraÃ§Ã£o de keys
- **Ãndices relacionados:** Ãndices em outras tabelas que referenciam a tabela analisada
- **Contexto completo:** Entender o design geral do banco ajuda a identificar padrÃµes problemÃ¡ticos
- **DependÃªncias:** Verificar se sequences/funÃ§Ãµes sÃ£o compartilhadas entre tabelas

**Exemplo de uso:**
```bash
# Obter DDL completa
FULL_DDL=$(get_full_database_ddl)

# FULL_DDL contÃ©m:
# CREATE SEQUENCE seq_members START COUNTER WITH 1;
# CREATE TABLE members (... DEFAULT GET_NEXT_SEQUENCE_VALUE(seq_members));
# CREATE TABLE orders (... DEFAULT GET_NEXT_SEQUENCE_VALUE(seq_members));
# CREATE INDEX idx_members_user ON members(user_id);
# CREATE FUNCTION generate_id() RETURNS INT64 AS (SELECT ...);
```

---

### 2. FunÃ§Ã£o: `get_table_metadata()`
**LocalizaÃ§Ã£o:** ApÃ³s `get_table_ddl()`

**Responsabilidade:**
- Obter metadados estruturados da tabela:
  - Primary Key (colunas, tipos, default values)
  - Ãndices secundÃ¡rios (nome, colunas, tipo)
  - Colunas (nome, tipo, nullable, default)
- Retornar JSON estruturado para facilitar anÃ¡lise

**Entrada:** `table_name`
**SaÃ­da:** JSON com metadados estruturados

**Estrutura JSON:**
```json
{
  "table_name": "members",
  "primary_key": {
    "columns": [
      {"name": "member_id", "type": "INT64", "default": "GET_NEXT_SEQUENCE_VALUE(...)"}
    ]
  },
  "indexes": [
    {"name": "idx_user", "type": "INDEX", "columns": ["user_id"]}
  ],
  "columns": [
    {"name": "member_id", "type": "INT64", "nullable": false, "default": "GET_NEXT_SEQUENCE_VALUE(...)"},
    {"name": "status", "type": "STRING(10)", "nullable": true}
  ]
}
```

---

### 3. FunÃ§Ã£o: `build_hotspot_prompt()`
**LocalizaÃ§Ã£o:** ApÃ³s `get_table_metadata()`

**Responsabilidade:**
- Construir prompt estruturado para a LLM
- Incluir contexto sobre hotspots no Spanner
- Incluir DDL COMPLETA do banco (todos os objetos)
- Incluir metadados da tabela especÃ­fica a ser analisada
- Definir formato de resposta esperado

**Entrada:** 
- `full_ddl` (string) - DDL completa do banco (tabelas, Ã­ndices, sequences, funÃ§Ãµes)
- `table_name` (string) - Nome da tabela a ser analisada
- `metadata` (JSON string) - Metadados da tabela especÃ­fica

**SaÃ­da:** Prompt completo para LLM

**Nota:** A DDL completa permite Ã  LLM:
- Identificar sequences compartilhadas
- Verificar se sequences sÃ£o usadas em outras tabelas
- Analisar funÃ§Ãµes customizadas usadas em defaults
- Entender contexto completo do banco

**Estrutura do Prompt:**
```
VocÃª Ã© um especialista em Google Cloud Spanner analisando hotspots.

CONTEXTO SOBRE HOTSPOTS:
1. SequÃªncia explÃ­cita (DEFAULT GET_NEXT_SEQUENCE_VALUE(...)) â†’ HOTSPOT QUASE CERTO
2. Timestamp como PK â†’ HOTSPOT QUASE CERTO
3. INT64 sem randomizaÃ§Ã£o â†’ Alto risco (80% dos casos viram hotspot)
4. STRING UUID â†’ Seguro

DDL COMPLETA DO BANCO DE DADOS:
[DDL completa aqui - inclui TODAS as tabelas, Ã­ndices, sequences e funÃ§Ãµes]

TABELA A ANALISAR: ${table_name}

METADADOS DA TABELA ESPECÃFICA:
[JSON metadata aqui - apenas da tabela sendo analisada]

IMPORTANTE:
- Analise a tabela "${table_name}" especificamente
- Considere o contexto completo do banco (sequences compartilhadas, etc)
- Verifique se sequences usadas na tabela sÃ£o compartilhadas com outras tabelas
- Analise funÃ§Ãµes customizadas que possam afetar a geraÃ§Ã£o de keys

Analise a tabela "${table_name}" e retorne JSON no formato:
{
  "table_name": "nome_tabela",
  "primary_key_analysis": {
    "columns": [{"name": "...", "type": "...", "default": "..."}],
    "classification": "HOTSPOT QUASE CERTO" | "Alto risco" | "Seguro",
    "risk_score": 0-100,
    "reason": "explicaÃ§Ã£o"
  },
  "secondary_indexes": [
    {
      "name": "...",
      "risk": "..." | null,
      "reason": "..."
    }
  ],
  "column_risks": [
    {"column": "...", "risk": "...", "reason": "..."}
  ],
  "final_score": 0-100,
  "risk_level": "ALTO" | "MÃ‰DIO" | "BAIXO",
  "recommendations": ["...", "..."]
}
```

---

### 4. FunÃ§Ã£o: `call_openai_api()`
**LocalizaÃ§Ã£o:** ApÃ³s `build_hotspot_prompt()`

**Responsabilidade:**
- Fazer chamada HTTP para API da OpenAI
- Usar configuraÃ§Ã£o LLM atual (provider, model, api_key)
- Tratar erros de API
- Retornar resposta JSON

**Entrada:**
- `prompt` (string)
- `model` (string, default: gpt-3.5-turbo)
- `api_key` (string)

**SaÃ­da:** JSON response da OpenAI

**ImplementaÃ§Ã£o:**
- Usar `curl` para fazer POST para `https://api.openai.com/v1/chat/completions`
- Headers: `Authorization: Bearer ${api_key}`, `Content-Type: application/json`
- Body: `{"model": "${model}", "messages": [{"role": "user", "content": "${prompt}"}], "temperature": 0.3, "response_format": {"type": "json_object"}}`
- Extrair `choices[0].message.content` da resposta

**Tratamento de Erros:**
- Verificar se `curl` estÃ¡ instalado
- Verificar se API key Ã© vÃ¡lida
- Verificar rate limits
- Timeout de 30 segundos

---

### 5. FunÃ§Ã£o: `format_hotspot_report()`
**LocalizaÃ§Ã£o:** ApÃ³s `call_openai_api()`

**Responsabilidade:**
- Processar resposta JSON da LLM
- Formatar saÃ­da similar ao exemplo fornecido
- Usar cores ANSI para destacar riscos
- Validar estrutura do JSON retornado

**Entrada:** JSON response da LLM
**SaÃ­da:** Texto formatado para exibiÃ§Ã£o

**Formato de SaÃ­da:**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”¥ HOTSPOT ANALYSIS â€” TABLE: members
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Primary Key:
- member_id (INT64)
- Default: SEQUENCE
âŒ ClassificaÃ§Ã£o: HOTSPOT QUASE CERTO

Secondary Indexes:
- idx_user â†’ Herda hotspot da PK
- idx_status â†’ Hotspot por baixa cardinalidade

Column Risks:
- status â†’ baixa cardinalidade
- type â†’ baixa cardinalidade

Score Final: 92 / 100
Risk Level: ğŸ”´ ALTO

âœ… RecomendaÃ§Ãµes:
- Substituir PK sequencial por UUID
- Usar hash(member_id) como prefixo
- Evitar Ã­ndices sobre colunas categÃ³ricas
```

---

### 6. Comando `\hotspot-ai <table>`
**LocalizaÃ§Ã£o:** ApÃ³s comando `\llm` (apÃ³s linha ~1721)

**Sintaxe:** `\hotspot-ai <table>` ou `\hotspot-ai <table> --verbose`

**Fluxo:**
1. Validar sintaxe do comando
2. Extrair nome da tabela
3. Validar se tabela existe
4. Verificar se LLM estÃ¡ configurada
5. Obter DDL COMPLETA do banco (todos os objetos)
6. Obter metadados da tabela especÃ­fica
7. Construir prompt (incluir DDL completa + metadados da tabela)
8. Chamar API OpenAI
9. Processar resposta
10. Formatar e exibir relatÃ³rio

**ValidaÃ§Ãµes:**
- Tabela deve existir
- LLM deve estar configurada
- `curl` deve estar instalado
- `jq` deve estar instalado (para processar JSON)

**Tratamento de Erros:**
- Tabela nÃ£o encontrada
- LLM nÃ£o configurada
- Erro na chamada da API
- Resposta invÃ¡lida da LLM
- Timeout

---

## ğŸ“ Detalhamento TÃ©cnico

### 1. ObtenÃ§Ã£o de DDL Completa
```bash
# Obter DDL COMPLETA do banco (todos os objetos)
# Usar comando existente \da internamente
FULL_DDL=$(gcloud spanner databases ddl describe ${DATABASE_ID} \
  --instance=${INSTANCE_ID} 2>/dev/null)

# Esta DDL inclui:
# - CREATE TABLE statements (todas as tabelas)
# - CREATE INDEX statements (todos os Ã­ndices)
# - CREATE SEQUENCE statements (todas as sequences)
# - CREATE FUNCTION statements (todas as funÃ§Ãµes)
```

### 2. ObtenÃ§Ã£o de Default Values
```sql
SELECT 
  column_name,
  spanner_type,
  column_default
FROM information_schema.columns 
WHERE table_name = '${TABLE_NAME}'
ORDER BY ordinal_position;
```

**Nota:** `column_default` pode conter `GET_NEXT_SEQUENCE_VALUE(...)` para detectar sequÃªncias.

### 3. Chamada Ã  API OpenAI
```bash
# Usar curl com JSON
RESPONSE=$(curl -s -w "\n%{http_code}" \
  -X POST "https://api.openai.com/v1/chat/completions" \
  -H "Authorization: Bearer ${API_KEY}" \
  -H "Content-Type: application/json" \
  -d "{
    \"model\": \"${MODEL}\",
    \"messages\": [{\"role\": \"user\", \"content\": \"${PROMPT}\"}],
    \"temperature\": 0.3,
    \"response_format\": {\"type\": \"json_object\"}
  }" \
  --max-time 30)

HTTP_CODE=$(echo "$RESPONSE" | tail -n 1)
BODY=$(echo "$RESPONSE" | sed '$d')

# Extrair conteÃºdo da resposta
CONTENT=$(echo "$BODY" | jq -r '.choices[0].message.content' 2>/dev/null)
```

### 4. Processamento de Resposta
```bash
# Validar JSON
if ! echo "$CONTENT" | jq . >/dev/null 2>&1; then
  echo "Erro: Resposta invÃ¡lida da LLM"
  return 1
fi

# Extrair campos
TABLE_NAME=$(echo "$CONTENT" | jq -r '.table_name')
FINAL_SCORE=$(echo "$CONTENT" | jq -r '.final_score')
RISK_LEVEL=$(echo "$CONTENT" | jq -r '.risk_level')
# ... etc
```

---

## ğŸ¨ FormataÃ§Ã£o de SaÃ­da

### Cores e SÃ­mbolos
- ğŸ”´ ALTO risco: `RED`
- ğŸŸ¡ MÃ‰DIO risco: `YELLOW` (adicionar ao cÃ³digo)
- ğŸŸ¢ BAIXO risco: `GREEN`
- âŒ Hotspot detectado: `RED`
- âœ… Seguro: `GREEN`
- âš ï¸ AtenÃ§Ã£o: `YELLOW`

### Estrutura Visual
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  (linha dupla)
ğŸ”¥ HOTSPOT ANALYSIS â€” TABLE: nome
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Primary Key:
- coluna (tipo)
- Default: valor
[classificaÃ§Ã£o]

Secondary Indexes:
- nome â†’ motivo

Column Risks:
- coluna â†’ motivo

Score Final: X / 100
Risk Level: [emoji] [nÃ­vel]

âœ… RecomendaÃ§Ãµes:
- item 1
- item 2
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

### Fase 1: FunÃ§Ãµes Auxiliares
- [ ] `get_full_database_ddl()` - Obter DDL completa do banco (todos os objetos)
- [ ] `get_table_metadata()` - Obter metadados estruturados da tabela especÃ­fica
- [ ] `build_hotspot_prompt()` - Construir prompt para LLM (incluir DDL completa + metadados)
- [ ] `call_openai_api()` - Chamar API OpenAI
- [ ] `format_hotspot_report()` - Formatar relatÃ³rio

### Fase 2: Comando Principal
- [ ] Implementar `\hotspot-ai <table>`
- [ ] ValidaÃ§Ãµes (tabela existe, LLM configurada, dependÃªncias)
- [ ] Tratamento de erros
- [ ] IntegraÃ§Ã£o com help (`\help`)

### Fase 3: Melhorias
- [ ] Adicionar cor YELLOW ao cÃ³digo
- [ ] Suporte a `--verbose` para mais detalhes
- [ ] Cache de resultados (opcional)
- [ ] ValidaÃ§Ã£o de resposta JSON da LLM
- [ ] Fallback se LLM retornar formato invÃ¡lido

### Fase 4: Testes
- [ ] Testar com tabela com PK sequencial
- [ ] Testar com tabela com PK timestamp
- [ ] Testar com tabela com PK UUID
- [ ] Testar com tabela sem PK
- [ ] Testar sem LLM configurada
- [ ] Testar com erro de API

---

## ğŸ” DependÃªncias

### Ferramentas NecessÃ¡rias
1. **curl** - Para chamadas HTTP Ã  API OpenAI
2. **jq** - Para processar JSON (jÃ¡ usado no projeto)
3. **LLM configurada** - Via `--llm-setup`

### VerificaÃ§Ãµes
```bash
# Verificar curl
if ! command -v curl >/dev/null 2>&1; then
  echo "âŒ curl is not installed"
  return 1
fi

# Verificar jq (jÃ¡ existe no cÃ³digo)
if ! command -v jq >/dev/null 2>&1; then
  echo "âŒ jq is not installed"
  return 1
fi

# Verificar LLM configurada
CURRENT_KEY=$(get_current_llm_api_key)
if [[ -z "$CURRENT_KEY" ]]; then
  echo "âŒ LLM not configured. Use: spanner-shell --llm-setup"
  return 1
fi
```

---

## ğŸ“Š Estrutura de Dados

### Prompt para LLM
```
VocÃª Ã© um especialista em Google Cloud Spanner analisando problemas de hotspot.

CONTEXTO:
Hotspots ocorrem quando muitas operaÃ§Ãµes de escrita concentram-se em uma Ãºnica partiÃ§Ã£o.
PadrÃµes que causam hotspots:
1. PRIMARY KEY sequencial (DEFAULT GET_NEXT_SEQUENCE_VALUE(...)) â†’ HOTSPOT QUASE CERTO
2. PRIMARY KEY com TIMESTAMP â†’ HOTSPOT QUASE CERTO  
3. PRIMARY KEY INT64 sem randomizaÃ§Ã£o â†’ Alto risco (80% dos casos viram hotspot)
4. PRIMARY KEY STRING UUID â†’ Seguro

DDL COMPLETA DO BANCO DE DADOS:
[DDL completa aqui - TODAS as tabelas, Ã­ndices, sequences e funÃ§Ãµes]

TABELA A ANALISAR: ${table_name}

Analise especificamente a tabela "${table_name}" considerando o contexto completo do banco e retorne JSON estruturado com:
- AnÃ¡lise da Primary Key
- AnÃ¡lise de Ã­ndices secundÃ¡rios
- Riscos por coluna
- Score final (0-100)
- NÃ­vel de risco (ALTO/MÃ‰DIO/BAIXO)
- RecomendaÃ§Ãµes especÃ­ficas

Formato JSON obrigatÃ³rio.
```

### Resposta Esperada da LLM
```json
{
  "table_name": "members",
  "primary_key_analysis": {
    "columns": [
      {
        "name": "member_id",
        "type": "INT64",
        "default": "GET_NEXT_SEQUENCE_VALUE(...)"
      }
    ],
    "classification": "HOTSPOT QUASE CERTO",
    "risk_score": 95,
    "reason": "PK usa sequÃªncia explÃ­cita que causa concentraÃ§Ã£o de writes"
  },
  "secondary_indexes": [
    {
      "name": "idx_user",
      "risk": "Herda hotspot da PK",
      "reason": "Ãndice inclui coluna da PK sequencial"
    },
    {
      "name": "idx_status",
      "risk": "Hotspot por baixa cardinalidade",
      "reason": "Coluna status tem poucos valores distintos"
    }
  ],
  "column_risks": [
    {
      "column": "status",
      "risk": "baixa cardinalidade",
      "reason": "Coluna categÃ³rica com poucos valores"
    }
  ],
  "final_score": 92,
  "risk_level": "ALTO",
  "recommendations": [
    "Substituir PK sequencial por UUID",
    "Usar hash(member_id) como prefixo",
    "Evitar Ã­ndices sobre colunas categÃ³ricas"
  ]
}
```

---

## ğŸš€ Ordem de ImplementaÃ§Ã£o

### Passo 1: Adicionar cor YELLOW
```bash
YELLOW='\033[0;33m'
```

### Passo 2: FunÃ§Ã£o `get_full_database_ddl()`
- Reutilizar lÃ³gica do `\da` (DDL completa)
- Retornar DDL completa como string
- Incluir todos os objetos: tabelas, Ã­ndices, sequences, funÃ§Ãµes

### Passo 3: FunÃ§Ã£o `get_table_metadata()`
- Query para obter default values
- Montar JSON estruturado

### Passo 4: FunÃ§Ã£o `build_hotspot_prompt()`
- Template do prompt
- Inserir DDL COMPLETA do banco (todos os objetos)
- Inserir metadados da tabela especÃ­fica
- Especificar qual tabela deve ser analisada

### Passo 5: FunÃ§Ã£o `call_openai_api()`
- Implementar chamada curl
- Tratamento de erros HTTP
- Extrair conteÃºdo da resposta

### Passo 6: FunÃ§Ã£o `format_hotspot_report()`
- Processar JSON da resposta
- Formatar saÃ­da bonita
- Usar cores apropriadas

### Passo 7: Comando `\hotspot-ai`
- Integrar todas as funÃ§Ãµes
- ValidaÃ§Ãµes
- Tratamento de erros
- Adicionar ao help

---

## ğŸ§ª Casos de Teste

### Teste 1: Tabela com PK Sequencial
```sql
CREATE TABLE test_seq (
  id INT64 NOT NULL DEFAULT (GET_NEXT_SEQUENCE_VALUE(SEQUENCE seq_test)),
  name STRING(255)
) PRIMARY KEY (id);
```
**Resultado esperado:** HOTSPOT QUASE CERTO, score alto

### Teste 2: Tabela com PK Timestamp
```sql
CREATE TABLE test_timestamp (
  created_at TIMESTAMP NOT NULL,
  data STRING(255)
) PRIMARY KEY (created_at);
```
**Resultado esperado:** HOTSPOT QUASE CERTO, score alto

### Teste 3: Tabela com PK UUID
```sql
CREATE TABLE test_uuid (
  id STRING(36) NOT NULL,
  name STRING(255)
) PRIMARY KEY (id);
```
**Resultado esperado:** Seguro, score baixo

### Teste 4: Tabela sem LLM configurada
**Resultado esperado:** Erro informando para configurar LLM

### Teste 5: Tabela inexistente
**Resultado esperado:** Erro informando tabela nÃ£o encontrada

---

## ğŸ“š ReferÃªncias

### API OpenAI
- Endpoint: `https://api.openai.com/v1/chat/completions`
- MÃ©todo: POST
- Headers: `Authorization: Bearer ${api_key}`, `Content-Type: application/json`
- Body: `{"model": "...", "messages": [...], "response_format": {"type": "json_object"}}`

### DocumentaÃ§Ã£o Spanner Hotspots
- [Spanner Hotspot Detection](https://cloud.google.com/spanner/docs/hotspot-detection)
- PadrÃµes de PK que causam hotspots
- Boas prÃ¡ticas de design

---

## ğŸ”„ Melhorias Futuras

1. **Cache de Resultados**
   - Salvar anÃ¡lises em arquivo temporÃ¡rio
   - Evitar re-anÃ¡lise da mesma tabela

2. **AnÃ¡lise de MÃºltiplas Tabelas**
   - `\hotspot-ai --all` para analisar todas as tabelas

3. **Exportar RelatÃ³rio**
   - `\hotspot-ai <table> --export report.json`

4. **Suporte a Outros Providers**
   - Claude (Anthropic)
   - Gemini (Google)

5. **AnÃ¡lise EstatÃ­stica**
   - Combinar anÃ¡lise LLM com dados reais de uso
   - Query para detectar distribuiÃ§Ã£o de keys

---

## ğŸ“ Notas de ImplementaÃ§Ã£o

### ConsideraÃ§Ãµes Importantes
1. **Timeout:** API pode demorar, usar timeout de 30s
2. **Rate Limits:** OpenAI tem limites, tratar erro 429
3. **Custos:** Cada chamada consome tokens, informar usuÃ¡rio
4. **Privacidade:** DDL pode conter informaÃ§Ãµes sensÃ­veis
5. **ValidaÃ§Ã£o:** Sempre validar JSON retornado pela LLM

### Tratamento de Erros EspecÃ­ficos
- **401 Unauthorized:** API key invÃ¡lida
- **429 Too Many Requests:** Rate limit excedido
- **500 Internal Server Error:** Erro do servidor OpenAI
- **Timeout:** Chamada demorou mais de 30s
- **JSON invÃ¡lido:** Resposta nÃ£o Ã© JSON vÃ¡lido
- **Campos faltando:** JSON nÃ£o tem estrutura esperada

---

## âœ… CritÃ©rios de Sucesso

1. âœ… Comando `\hotspot-ai <table>` funciona corretamente
2. âœ… Identifica corretamente PK sequencial
3. âœ… Identifica corretamente PK timestamp
4. âœ… Identifica corretamente PK UUID como seguro
5. âœ… Formata saÃ­da similar ao exemplo fornecido
6. âœ… Trata erros de forma elegante
7. âœ… Integrado ao sistema de help
8. âœ… Documentado no README

---

**Data de CriaÃ§Ã£o:** 2024
**VersÃ£o do Plano:** 1.0
